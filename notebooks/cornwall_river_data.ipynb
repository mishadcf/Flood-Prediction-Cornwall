{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from data_collection import fetch_and_save_river_data\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornwall_stations = pd.read_csv('river_station_info_cornwall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[380,\n",
       " 382,\n",
       " 384,\n",
       " 386,\n",
       " 387,\n",
       " 391,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 1349,\n",
       " 1351,\n",
       " 1352,\n",
       " 8256,\n",
       " 8340,\n",
       " 16446,\n",
       " 17891,\n",
       " 355,\n",
       " 357,\n",
       " 358,\n",
       " 361,\n",
       " 362,\n",
       " 364,\n",
       " 365,\n",
       " 370,\n",
       " 375,\n",
       " 1335,\n",
       " 1339,\n",
       " 1340,\n",
       " 1341,\n",
       " 1342,\n",
       " 8227,\n",
       " 14453,\n",
       " 14454]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_ids = cornwall_stations.id.to_list()\n",
    "station_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2000, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current date\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Yesterday's date\n",
    "yesterday = now - datetime.timedelta(days=1)\n",
    "\n",
    "# Start date as January 1st, 2000\n",
    "start_date = datetime.datetime(2000, 1, 1)\n",
    "\n",
    "# Format the dates to the ISO 8601 format (as strings)\n",
    "start_date_str = start_date.strftime('%Y-%m-%dT%H')\n",
    "yesterday_str = yesterday.strftime('%Y-%m-%dT%H')\n",
    "\n",
    "start_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for station 355 saved successfully in get_river_data/data/station_355.csv.\n"
     ]
    }
   ],
   "source": [
    "fetch_and_save_river_data(station_ids=[355], start_date=start_date, end_date=yesterday)\n",
    "from transform_data import extract_time_values_from_csv\n",
    "cleaned = extract_time_values_from_csv('/Users/antonfreidin/water_project/get_river_data/data/station_355.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.to_csv('gpt_355.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for station 380 saved successfully in get_river_data/data/station_380.csv.\n",
      "Data for station 382 saved successfully in get_river_data/data/station_382.csv.\n",
      "Data for station 384 saved successfully in get_river_data/data/station_384.csv.\n",
      "Request failed for station 386, status code: 500\n",
      "Data for station 387 saved successfully in get_river_data/data/station_387.csv.\n",
      "Request failed for station 391, status code: 500\n",
      "Data for station 393 saved successfully in get_river_data/data/station_393.csv.\n",
      "Data for station 394 saved successfully in get_river_data/data/station_394.csv.\n",
      "Data for station 395 saved successfully in get_river_data/data/station_395.csv.\n",
      "Data for station 397 saved successfully in get_river_data/data/station_397.csv.\n",
      "Data for station 398 saved successfully in get_river_data/data/station_398.csv.\n",
      "Request failed for station 399, status code: 500\n",
      "Data for station 400 saved successfully in get_river_data/data/station_400.csv.\n",
      "Request failed for station 1349, status code: 500\n",
      "Data for station 1351 saved successfully in get_river_data/data/station_1351.csv.\n",
      "Data for station 1352 saved successfully in get_river_data/data/station_1352.csv.\n",
      "Data for station 8256 saved successfully in get_river_data/data/station_8256.csv.\n",
      "Data for station 8340 saved successfully in get_river_data/data/station_8340.csv.\n",
      "Request failed for station 16446, status code: 500\n",
      "Data for station 17891 saved successfully in get_river_data/data/station_17891.csv.\n",
      "Data for station 355 saved successfully in get_river_data/data/station_355.csv.\n",
      "Data for station 357 saved successfully in get_river_data/data/station_357.csv.\n",
      "Request failed for station 358, status code: 500\n",
      "Data for station 361 saved successfully in get_river_data/data/station_361.csv.\n",
      "Data for station 362 saved successfully in get_river_data/data/station_362.csv.\n",
      "Data for station 364 saved successfully in get_river_data/data/station_364.csv.\n",
      "Data for station 365 saved successfully in get_river_data/data/station_365.csv.\n",
      "Data for station 370 saved successfully in get_river_data/data/station_370.csv.\n",
      "Request failed for station 375, status code: 500\n",
      "Data for station 1335 saved successfully in get_river_data/data/station_1335.csv.\n",
      "Data for station 1339 saved successfully in get_river_data/data/station_1339.csv.\n",
      "Data for station 1340 saved successfully in get_river_data/data/station_1340.csv.\n",
      "Data for station 1341 saved successfully in get_river_data/data/station_1341.csv.\n",
      "Data for station 1342 saved successfully in get_river_data/data/station_1342.csv.\n",
      "Data for station 8227 saved successfully in get_river_data/data/station_8227.csv.\n",
      "Data for station 14453 saved successfully in get_river_data/data/station_14453.csv.\n",
      "Data for station 14454 saved successfully in get_river_data/data/station_14454.csv.\n"
     ]
    }
   ],
   "source": [
    "fetch_and_save_river_data(station_ids=station_ids, start_date=start_date, end_date=yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = [386,391,399,1349,16446,358,375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for station 386, status code: 500\n",
      "Request failed for station 391, status code: 500\n",
      "Request failed for station 399, status code: 500\n",
      "Request failed for station 1349, status code: 500\n",
      "Request failed for station 16446, status code: 500\n",
      "Request failed for station 358, status code: 500\n",
      "Request failed for station 375, status code: 500\n"
     ]
    }
   ],
   "source": [
    "fetch_and_save_river_data(station_ids=failed, start_date=start_date, end_date=yesterday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('get_river_data/data/station_8256.csv', usecols=['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "                                            values\n",
      "0  {'time': '2014-03-04T04:15:00', 'value': 0.249}\n",
      "0  {'time': '2014-03-04T04:30:00', 'value': 0.244}\n",
      "0  {'time': '2014-03-04T04:45:00', 'value': 0.245}\n",
      "0  {'time': '2014-03-04T05:00:00', 'value': 0.241}\n",
      "0  {'time': '2014-03-04T05:15:00', 'value': 0.245}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Safety check: ensure the column is not aggregated into one entry\n",
    "print(df.shape)  # Should show more than 1 row if data is spread across multiple rows\n",
    "\n",
    "# Convert string representation of lists into actual lists of dictionaries\n",
    "df['values'] = df['values'].apply(ast.literal_eval)\n",
    "\n",
    "# Exploding the list into rows\n",
    "df = df.explode('values')\n",
    "\n",
    "# Display the result\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time  value\n",
      "0 2014-03-04 04:15:00  0.249\n",
      "0 2014-03-04 04:30:00  0.244\n",
      "0 2014-03-04 04:45:00  0.245\n",
      "0 2014-03-04 05:00:00  0.241\n",
      "0 2014-03-04 05:15:00  0.245\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 227880 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype         \n",
      "---  ------  --------------   -----         \n",
      " 0   time    227880 non-null  datetime64[ns]\n",
      " 1   value   227880 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 5.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame after the literal_eval step\n",
    "# If the DataFrame has not been exploded properly (which it should as per your data sample):\n",
    "if not isinstance(df.at[0, 'values'], list):\n",
    "    df['values'] = df['values'].apply(lambda x: [x])  # Ensure it's a list\n",
    "df = df.explode('values')  # Now explode the DataFrame\n",
    "\n",
    "# Convert dictionaries to separate columns\n",
    "df = pd.concat([df.drop('values', axis=1), df['values'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# Convert 'time' to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Display the DataFrame structure\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-04 04:15:00</th>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 04:30:00</th>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 04:45:00</th>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 05:00:00</th>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 05:15:00</th>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-23 03:00:00</th>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-23 03:15:00</th>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-23 03:30:00</th>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-23 03:45:00</th>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-23 04:00:00</th>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227880 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "time                      \n",
       "2014-03-04 04:15:00  0.249\n",
       "2014-03-04 04:30:00  0.244\n",
       "2014-03-04 04:45:00  0.245\n",
       "2014-03-04 05:00:00  0.241\n",
       "2014-03-04 05:15:00  0.245\n",
       "...                    ...\n",
       "2023-11-23 03:00:00  0.551\n",
       "2023-11-23 03:15:00  0.559\n",
       "2023-11-23 03:30:00  0.552\n",
       "2023-11-23 03:45:00  0.548\n",
       "2023-11-23 04:00:00  0.555\n",
       "\n",
       "[227880 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waterfall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
