{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling highest granularity data for river gauges, cleaning and pulling new coastal gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data_collection as dc\n",
    "from src.data_preprocessing import extract_time_values_from_csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01T00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Define the date string\n",
    "date_str = \"1 Jan 2016\"\n",
    "\n",
    "# Parse the date string and convert it to ISO 8601 format\n",
    "date_iso8601 = datetime.strptime(date_str, \"%d %b %Y\").isoformat()\n",
    "\n",
    "print(date_iso8601)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_top_level_info_river_gauges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for station 368 saved successfully in data/river_data/station_368.csv.\n"
     ]
    }
   ],
   "source": [
    "dc.fetch_and_save_river_data(station_ids=[368], smoothing=0,end_date=today, start_date=date_iso8601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_368 = pd.read_csv('data/river_data/station_368.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_368 = extract_time_values_from_csv('data/river_data/station_368.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:15:00</th>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:30:00</th>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:45:00</th>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 10:00:00</th>\n",
       "      <td>-0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 10:15:00</th>\n",
       "      <td>-0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 10:30:00</th>\n",
       "      <td>-0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 10:45:00</th>\n",
       "      <td>-2.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 13:00:00</th>\n",
       "      <td>-2.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257621 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "time                      \n",
       "2016-01-01 00:00:00  0.728\n",
       "2016-01-01 00:15:00  0.595\n",
       "2016-01-01 00:30:00  0.390\n",
       "2016-01-01 00:45:00  0.198\n",
       "2016-01-01 01:00:00  0.055\n",
       "...                    ...\n",
       "2024-06-18 10:00:00 -0.436\n",
       "2024-06-18 10:15:00 -0.437\n",
       "2024-06-18 10:30:00 -0.437\n",
       "2024-06-18 10:45:00 -2.385\n",
       "2024-06-18 13:00:00 -2.385\n",
       "\n",
       "[257621 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for station 368 saved successfully in data/river_data/station_368.csv.\n"
     ]
    }
   ],
   "source": [
    "dc.fetch_and_save_river_data(station_ids=[368], smoothing=2,end_date=today, start_date=date_iso8601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_368 = extract_time_values_from_csv('data/river_data/station_368.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:15:00</th>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:45:00</th>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:15:00</th>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 06:30:00</th>\n",
       "      <td>-0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 06:45:00</th>\n",
       "      <td>-0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 10:30:00</th>\n",
       "      <td>-0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 10:45:00</th>\n",
       "      <td>-2.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 13:00:00</th>\n",
       "      <td>-2.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144766 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "time                      \n",
       "2016-01-01 00:00:00  0.728\n",
       "2016-01-01 00:15:00  0.595\n",
       "2016-01-01 00:45:00  0.198\n",
       "2016-01-01 01:00:00  0.055\n",
       "2016-01-01 01:15:00  0.075\n",
       "...                    ...\n",
       "2024-06-18 06:30:00 -0.421\n",
       "2024-06-18 06:45:00 -0.434\n",
       "2024-06-18 10:30:00 -0.437\n",
       "2024-06-18 10:45:00 -2.385\n",
       "2024-06-18 13:00:00 -2.385\n",
       "\n",
       "[144766 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to pull all the river data again with 0 smoothing...! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('data/river_data/river_station_info_cornwall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stationOwner</th>\n",
       "      <th>state</th>\n",
       "      <th>updatedTime</th>\n",
       "      <th>additionalDataObject</th>\n",
       "      <th>gaugeList</th>\n",
       "      <th>stationWaterLevelStatisticsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380</td>\n",
       "      <td>Denby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.479652</td>\n",
       "      <td>-4.795633</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-12T16:29:18.047</td>\n",
       "      <td>{'stationReference': '49109', 'catchmentName':...</td>\n",
       "      <td>[{'id': 388, 'geoEntityId': 380, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382</td>\n",
       "      <td>Helebridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.806427</td>\n",
       "      <td>-4.536459</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T10:38:41.86</td>\n",
       "      <td>{'stationReference': '49111', 'catchmentName':...</td>\n",
       "      <td>[{'id': 390, 'geoEntityId': 382, 'dataTypeId':...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>Bush</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.844487</td>\n",
       "      <td>-4.509160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:34:57.52</td>\n",
       "      <td>{'stationReference': '49113', 'catchmentName':...</td>\n",
       "      <td>[{'id': 391, 'geoEntityId': 384, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>Padstow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.541745</td>\n",
       "      <td>-4.936932</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:41:31.21</td>\n",
       "      <td>{'stationReference': '49116', 'catchmentName':...</td>\n",
       "      <td>[{'id': 393, 'geoEntityId': 386, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387</td>\n",
       "      <td>Penvose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.566819</td>\n",
       "      <td>-4.750514</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:32:55.55</td>\n",
       "      <td>{'stationReference': '49117', 'catchmentName':...</td>\n",
       "      <td>[{'id': 394, 'geoEntityId': 387, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>391</td>\n",
       "      <td>Wadebridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.516704</td>\n",
       "      <td>-4.834983</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:36:23.353</td>\n",
       "      <td>{'stationReference': '49122', 'catchmentName':...</td>\n",
       "      <td>[{'id': 398, 'geoEntityId': 391, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>393</td>\n",
       "      <td>De Lank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.558805</td>\n",
       "      <td>-4.637791</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T09:34:29.83</td>\n",
       "      <td>{'stationReference': '49129', 'catchmentName':...</td>\n",
       "      <td>[{'id': 400, 'geoEntityId': 393, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>394</td>\n",
       "      <td>Gwills</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.393216</td>\n",
       "      <td>-5.056212</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T09:34:56.163</td>\n",
       "      <td>{'stationReference': '49130', 'catchmentName':...</td>\n",
       "      <td>[{'id': 401, 'geoEntityId': 394, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>395</td>\n",
       "      <td>Slaughterbridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.640434</td>\n",
       "      <td>-4.675177</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-12T14:48:50.117</td>\n",
       "      <td>{'stationReference': '49131', 'catchmentName':...</td>\n",
       "      <td>[{'id': 402, 'geoEntityId': 395, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>397</td>\n",
       "      <td>Sladesbridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.509313</td>\n",
       "      <td>-4.804805</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:44:06.73</td>\n",
       "      <td>{'stationReference': '49133', 'catchmentName':...</td>\n",
       "      <td>[{'id': 404, 'geoEntityId': 397, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>398</td>\n",
       "      <td>Woolstone Mill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.788694</td>\n",
       "      <td>-4.516344</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:40:51.163</td>\n",
       "      <td>{'stationReference': '49134', 'catchmentName':...</td>\n",
       "      <td>[{'id': 405, 'geoEntityId': 398, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>399</td>\n",
       "      <td>Bude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.832974</td>\n",
       "      <td>-4.558848</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-11T06:21:38.3</td>\n",
       "      <td>{'stationReference': '49150', 'catchmentName':...</td>\n",
       "      <td>[{'id': 406, 'geoEntityId': 399, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>Bodmin Band Club</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.471406</td>\n",
       "      <td>-4.717345</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T11:11:48.783</td>\n",
       "      <td>{'stationReference': '49152', 'catchmentName':...</td>\n",
       "      <td>[{'id': 407, 'geoEntityId': 400, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1349</td>\n",
       "      <td>Boscastle New Mills</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.691085</td>\n",
       "      <td>-4.694201</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:50:06.32</td>\n",
       "      <td>{'stationReference': '49124', 'catchmentName':...</td>\n",
       "      <td>[{'id': 11219, 'geoEntityId': 1349, 'dataTypeI...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1351</td>\n",
       "      <td>Bodmin St Petrocs Well</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.468464</td>\n",
       "      <td>-4.713131</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T11:35:45.107</td>\n",
       "      <td>{'stationReference': '49153', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1495, 'geoEntityId': 1351, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1352</td>\n",
       "      <td>Port Isaac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.589167</td>\n",
       "      <td>-4.830222</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T09:42:49.993</td>\n",
       "      <td>{'stationReference': '49170', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1496, 'geoEntityId': 1352, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8256</td>\n",
       "      <td>BOSCASTLE ANDERTON FORD</td>\n",
       "      <td>Discovered</td>\n",
       "      <td>50.691200</td>\n",
       "      <td>-4.638040</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-23T04:42:19.063</td>\n",
       "      <td>{'stationReference': '49173', 'catchmentName':...</td>\n",
       "      <td>[{'id': 3601, 'geoEntityId': 8256, 'dataTypeId...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8340</td>\n",
       "      <td>BOSCASTLE COUNTY BRIDGE</td>\n",
       "      <td>Discovered</td>\n",
       "      <td>50.689900</td>\n",
       "      <td>-4.693030</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:52:59.603</td>\n",
       "      <td>{'stationReference': '49174', 'catchmentName':...</td>\n",
       "      <td>[{'id': 3683, 'geoEntityId': 8340, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16446</td>\n",
       "      <td>Nanstallon</td>\n",
       "      <td>Imported</td>\n",
       "      <td>50.472778</td>\n",
       "      <td>-4.783056</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-01T00:50:38.11</td>\n",
       "      <td>{'stationReference': 'FD_00004', 'farsonId': '...</td>\n",
       "      <td>[{'id': 12166, 'geoEntityId': 16446, 'dataType...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17891</td>\n",
       "      <td>BODMIN DUNMERE</td>\n",
       "      <td>Discovered</td>\n",
       "      <td>50.474140</td>\n",
       "      <td>-4.757109</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T08:11:46.24</td>\n",
       "      <td>{'stationReference': '49182', 'region': 'South...</td>\n",
       "      <td>[{'id': 13596, 'geoEntityId': 17891, 'dataType...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>355</td>\n",
       "      <td>Rose in Vale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.312000</td>\n",
       "      <td>-5.166148</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:36:36.52</td>\n",
       "      <td>{'stationReference': '48107', 'catchmentName':...</td>\n",
       "      <td>[{'id': 365, 'geoEntityId': 355, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>357</td>\n",
       "      <td>Bolingey Cocks Bridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.333427</td>\n",
       "      <td>-5.144356</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:35:57.987</td>\n",
       "      <td>{'stationReference': '48110', 'catchmentName':...</td>\n",
       "      <td>[{'id': 367, 'geoEntityId': 357, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>358</td>\n",
       "      <td>Hayle Tideflap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.175828</td>\n",
       "      <td>-5.436540</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T11:09:33.64</td>\n",
       "      <td>{'stationReference': '48113', 'catchmentName':...</td>\n",
       "      <td>[{'id': 368, 'geoEntityId': 358, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>361</td>\n",
       "      <td>Loe Pool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.083629</td>\n",
       "      <td>-5.291197</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-09T04:38:35.72</td>\n",
       "      <td>{'stationReference': '48117', 'catchmentName':...</td>\n",
       "      <td>[{'id': 371, 'geoEntityId': 361, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>362</td>\n",
       "      <td>Perrancoombe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.340205</td>\n",
       "      <td>-5.157454</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:36:22.4</td>\n",
       "      <td>{'stationReference': '48121', 'catchmentName':...</td>\n",
       "      <td>[{'id': 372, 'geoEntityId': 362, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>364</td>\n",
       "      <td>Relubbus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.137450</td>\n",
       "      <td>-5.406954</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T11:34:52</td>\n",
       "      <td>{'stationReference': '48124', 'catchmentName':...</td>\n",
       "      <td>[{'id': 374, 'geoEntityId': 364, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>365</td>\n",
       "      <td>St Erth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.156890</td>\n",
       "      <td>-5.432912</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:36:00.45</td>\n",
       "      <td>{'stationReference': '48125', 'catchmentName':...</td>\n",
       "      <td>[{'id': 375, 'geoEntityId': 365, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>370</td>\n",
       "      <td>Boscadjack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.131134</td>\n",
       "      <td>-5.255314</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:41:33.77</td>\n",
       "      <td>{'stationReference': '48138', 'catchmentName':...</td>\n",
       "      <td>[{'id': 380, 'geoEntityId': 370, 'dataTypeId':...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>375</td>\n",
       "      <td>St Ives Tide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.215241</td>\n",
       "      <td>-5.476416</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:47:02.78</td>\n",
       "      <td>{'stationReference': '48160', 'catchmentName':...</td>\n",
       "      <td>[{'id': 385, 'geoEntityId': 375, 'dataTypeId':...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1335</td>\n",
       "      <td>Helston County Bridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.100039</td>\n",
       "      <td>-5.279763</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T10:34:29.32</td>\n",
       "      <td>{'stationReference': '48172', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1479, 'geoEntityId': 1335, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1339</td>\n",
       "      <td>Gwithian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.229604</td>\n",
       "      <td>-5.388672</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:42:39.953</td>\n",
       "      <td>{'stationReference': '48186', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1483, 'geoEntityId': 1339, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1340</td>\n",
       "      <td>St Ives Consols Farm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.206032</td>\n",
       "      <td>-5.498455</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T11:35:10.477</td>\n",
       "      <td>{'stationReference': '48187', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1484, 'geoEntityId': 1340, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1341</td>\n",
       "      <td>Penzance Alverton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.117386</td>\n",
       "      <td>-5.552427</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:54:58.68</td>\n",
       "      <td>{'stationReference': '48188', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1485, 'geoEntityId': 1341, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1342</td>\n",
       "      <td>Penzance Tesco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.126761</td>\n",
       "      <td>-5.525300</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:41:01.247</td>\n",
       "      <td>{'stationReference': '48189', 'catchmentName':...</td>\n",
       "      <td>[{'id': 1486, 'geoEntityId': 1342, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8227</td>\n",
       "      <td>TRENEAR</td>\n",
       "      <td>Discovered</td>\n",
       "      <td>50.131300</td>\n",
       "      <td>-5.338420</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T04:37:22.763</td>\n",
       "      <td>{'stationReference': '48126', 'catchmentName':...</td>\n",
       "      <td>[{'id': 3573, 'geoEntityId': 8227, 'dataTypeId...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>14453</td>\n",
       "      <td>PORTREATH</td>\n",
       "      <td>Discovered</td>\n",
       "      <td>50.260100</td>\n",
       "      <td>-5.279220</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:42:17.227</td>\n",
       "      <td>{'stationReference': '48174', 'catchmentName':...</td>\n",
       "      <td>[{'id': 9882, 'geoEntityId': 14453, 'dataTypeI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14454</td>\n",
       "      <td>PENBERTH</td>\n",
       "      <td>Discovered</td>\n",
       "      <td>50.050300</td>\n",
       "      <td>-5.633470</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-10T06:42:52.647</td>\n",
       "      <td>{'stationReference': '48173', 'catchmentName':...</td>\n",
       "      <td>[{'id': 9883, 'geoEntityId': 14454, 'dataTypeI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     name description   latitude  longitude  \\\n",
       "0     380                    Denby         NaN  50.479652  -4.795633   \n",
       "1     382               Helebridge         NaN  50.806427  -4.536459   \n",
       "2     384                     Bush         NaN  50.844487  -4.509160   \n",
       "3     386                  Padstow         NaN  50.541745  -4.936932   \n",
       "4     387                  Penvose         NaN  50.566819  -4.750514   \n",
       "5     391               Wadebridge         NaN  50.516704  -4.834983   \n",
       "6     393                  De Lank         NaN  50.558805  -4.637791   \n",
       "7     394                   Gwills         NaN  50.393216  -5.056212   \n",
       "8     395          Slaughterbridge         NaN  50.640434  -4.675177   \n",
       "9     397             Sladesbridge         NaN  50.509313  -4.804805   \n",
       "10    398           Woolstone Mill         NaN  50.788694  -4.516344   \n",
       "11    399                     Bude         NaN  50.832974  -4.558848   \n",
       "12    400         Bodmin Band Club         NaN  50.471406  -4.717345   \n",
       "13   1349      Boscastle New Mills         NaN  50.691085  -4.694201   \n",
       "14   1351   Bodmin St Petrocs Well         NaN  50.468464  -4.713131   \n",
       "15   1352               Port Isaac         NaN  50.589167  -4.830222   \n",
       "16   8256  BOSCASTLE ANDERTON FORD  Discovered  50.691200  -4.638040   \n",
       "17   8340  BOSCASTLE COUNTY BRIDGE  Discovered  50.689900  -4.693030   \n",
       "18  16446               Nanstallon  Imported    50.472778  -4.783056   \n",
       "19  17891           BODMIN DUNMERE  Discovered  50.474140  -4.757109   \n",
       "20    355             Rose in Vale         NaN  50.312000  -5.166148   \n",
       "21    357    Bolingey Cocks Bridge         NaN  50.333427  -5.144356   \n",
       "22    358           Hayle Tideflap         NaN  50.175828  -5.436540   \n",
       "23    361                 Loe Pool         NaN  50.083629  -5.291197   \n",
       "24    362             Perrancoombe         NaN  50.340205  -5.157454   \n",
       "25    364                 Relubbus         NaN  50.137450  -5.406954   \n",
       "26    365                  St Erth         NaN  50.156890  -5.432912   \n",
       "27    370               Boscadjack         NaN  50.131134  -5.255314   \n",
       "28    375             St Ives Tide         NaN  50.215241  -5.476416   \n",
       "29   1335    Helston County Bridge         NaN  50.100039  -5.279763   \n",
       "30   1339                 Gwithian         NaN  50.229604  -5.388672   \n",
       "31   1340     St Ives Consols Farm         NaN  50.206032  -5.498455   \n",
       "32   1341        Penzance Alverton         NaN  50.117386  -5.552427   \n",
       "33   1342           Penzance Tesco         NaN  50.126761  -5.525300   \n",
       "34   8227                  TRENEAR  Discovered  50.131300  -5.338420   \n",
       "35  14453                PORTREATH  Discovered  50.260100  -5.279220   \n",
       "36  14454                 PENBERTH  Discovered  50.050300  -5.633470   \n",
       "\n",
       "    stationOwner  state              updatedTime  \\\n",
       "0              3      0  2019-03-12T16:29:18.047   \n",
       "1              3      0   2024-07-10T10:38:41.86   \n",
       "2              3      0   2024-07-10T06:34:57.52   \n",
       "3              3      0   2024-07-10T04:41:31.21   \n",
       "4              3      0   2024-07-10T04:32:55.55   \n",
       "5              3      0  2024-07-10T04:36:23.353   \n",
       "6              3      0   2024-07-10T09:34:29.83   \n",
       "7              3      0  2024-07-10T09:34:56.163   \n",
       "8              3      0  2022-01-12T14:48:50.117   \n",
       "9              3      0   2024-07-10T06:44:06.73   \n",
       "10             3      0  2024-07-10T06:40:51.163   \n",
       "11             3      0    2020-06-11T06:21:38.3   \n",
       "12             3      0  2024-07-10T11:11:48.783   \n",
       "13             3      0   2024-07-10T04:50:06.32   \n",
       "14             3      0  2024-07-10T11:35:45.107   \n",
       "15             3      0  2024-07-10T09:42:49.993   \n",
       "16             3      0  2023-11-23T04:42:19.063   \n",
       "17             3      0  2024-07-10T04:52:59.603   \n",
       "18            44      0   2022-03-01T00:50:38.11   \n",
       "19             3      0   2024-07-10T08:11:46.24   \n",
       "20             3      0   2024-07-10T04:36:36.52   \n",
       "21             3      0  2024-07-10T06:35:57.987   \n",
       "22             3      0   2024-07-10T11:09:33.64   \n",
       "23             3      0   2024-07-09T04:38:35.72   \n",
       "24             3      0    2024-07-10T04:36:22.4   \n",
       "25             3      0      2024-07-10T11:34:52   \n",
       "26             3      0   2024-07-10T06:36:00.45   \n",
       "27             3      0   2024-07-10T04:41:33.77   \n",
       "28             3      0   2024-07-10T04:47:02.78   \n",
       "29             3      0   2024-07-10T10:34:29.32   \n",
       "30             3      0  2024-07-10T06:42:39.953   \n",
       "31             3      0  2024-07-10T11:35:10.477   \n",
       "32             3      0   2024-07-10T06:54:58.68   \n",
       "33             3      0  2024-07-10T06:41:01.247   \n",
       "34             3      0  2024-07-10T04:37:22.763   \n",
       "35             3      0  2024-07-10T06:42:17.227   \n",
       "36             3      0  2024-07-10T06:42:52.647   \n",
       "\n",
       "                                 additionalDataObject  \\\n",
       "0   {'stationReference': '49109', 'catchmentName':...   \n",
       "1   {'stationReference': '49111', 'catchmentName':...   \n",
       "2   {'stationReference': '49113', 'catchmentName':...   \n",
       "3   {'stationReference': '49116', 'catchmentName':...   \n",
       "4   {'stationReference': '49117', 'catchmentName':...   \n",
       "5   {'stationReference': '49122', 'catchmentName':...   \n",
       "6   {'stationReference': '49129', 'catchmentName':...   \n",
       "7   {'stationReference': '49130', 'catchmentName':...   \n",
       "8   {'stationReference': '49131', 'catchmentName':...   \n",
       "9   {'stationReference': '49133', 'catchmentName':...   \n",
       "10  {'stationReference': '49134', 'catchmentName':...   \n",
       "11  {'stationReference': '49150', 'catchmentName':...   \n",
       "12  {'stationReference': '49152', 'catchmentName':...   \n",
       "13  {'stationReference': '49124', 'catchmentName':...   \n",
       "14  {'stationReference': '49153', 'catchmentName':...   \n",
       "15  {'stationReference': '49170', 'catchmentName':...   \n",
       "16  {'stationReference': '49173', 'catchmentName':...   \n",
       "17  {'stationReference': '49174', 'catchmentName':...   \n",
       "18  {'stationReference': 'FD_00004', 'farsonId': '...   \n",
       "19  {'stationReference': '49182', 'region': 'South...   \n",
       "20  {'stationReference': '48107', 'catchmentName':...   \n",
       "21  {'stationReference': '48110', 'catchmentName':...   \n",
       "22  {'stationReference': '48113', 'catchmentName':...   \n",
       "23  {'stationReference': '48117', 'catchmentName':...   \n",
       "24  {'stationReference': '48121', 'catchmentName':...   \n",
       "25  {'stationReference': '48124', 'catchmentName':...   \n",
       "26  {'stationReference': '48125', 'catchmentName':...   \n",
       "27  {'stationReference': '48138', 'catchmentName':...   \n",
       "28  {'stationReference': '48160', 'catchmentName':...   \n",
       "29  {'stationReference': '48172', 'catchmentName':...   \n",
       "30  {'stationReference': '48186', 'catchmentName':...   \n",
       "31  {'stationReference': '48187', 'catchmentName':...   \n",
       "32  {'stationReference': '48188', 'catchmentName':...   \n",
       "33  {'stationReference': '48189', 'catchmentName':...   \n",
       "34  {'stationReference': '48126', 'catchmentName':...   \n",
       "35  {'stationReference': '48174', 'catchmentName':...   \n",
       "36  {'stationReference': '48173', 'catchmentName':...   \n",
       "\n",
       "                                            gaugeList  \\\n",
       "0   [{'id': 388, 'geoEntityId': 380, 'dataTypeId':...   \n",
       "1   [{'id': 390, 'geoEntityId': 382, 'dataTypeId':...   \n",
       "2   [{'id': 391, 'geoEntityId': 384, 'dataTypeId':...   \n",
       "3   [{'id': 393, 'geoEntityId': 386, 'dataTypeId':...   \n",
       "4   [{'id': 394, 'geoEntityId': 387, 'dataTypeId':...   \n",
       "5   [{'id': 398, 'geoEntityId': 391, 'dataTypeId':...   \n",
       "6   [{'id': 400, 'geoEntityId': 393, 'dataTypeId':...   \n",
       "7   [{'id': 401, 'geoEntityId': 394, 'dataTypeId':...   \n",
       "8   [{'id': 402, 'geoEntityId': 395, 'dataTypeId':...   \n",
       "9   [{'id': 404, 'geoEntityId': 397, 'dataTypeId':...   \n",
       "10  [{'id': 405, 'geoEntityId': 398, 'dataTypeId':...   \n",
       "11  [{'id': 406, 'geoEntityId': 399, 'dataTypeId':...   \n",
       "12  [{'id': 407, 'geoEntityId': 400, 'dataTypeId':...   \n",
       "13  [{'id': 11219, 'geoEntityId': 1349, 'dataTypeI...   \n",
       "14  [{'id': 1495, 'geoEntityId': 1351, 'dataTypeId...   \n",
       "15  [{'id': 1496, 'geoEntityId': 1352, 'dataTypeId...   \n",
       "16  [{'id': 3601, 'geoEntityId': 8256, 'dataTypeId...   \n",
       "17  [{'id': 3683, 'geoEntityId': 8340, 'dataTypeId...   \n",
       "18  [{'id': 12166, 'geoEntityId': 16446, 'dataType...   \n",
       "19  [{'id': 13596, 'geoEntityId': 17891, 'dataType...   \n",
       "20  [{'id': 365, 'geoEntityId': 355, 'dataTypeId':...   \n",
       "21  [{'id': 367, 'geoEntityId': 357, 'dataTypeId':...   \n",
       "22  [{'id': 368, 'geoEntityId': 358, 'dataTypeId':...   \n",
       "23  [{'id': 371, 'geoEntityId': 361, 'dataTypeId':...   \n",
       "24  [{'id': 372, 'geoEntityId': 362, 'dataTypeId':...   \n",
       "25  [{'id': 374, 'geoEntityId': 364, 'dataTypeId':...   \n",
       "26  [{'id': 375, 'geoEntityId': 365, 'dataTypeId':...   \n",
       "27  [{'id': 380, 'geoEntityId': 370, 'dataTypeId':...   \n",
       "28  [{'id': 385, 'geoEntityId': 375, 'dataTypeId':...   \n",
       "29  [{'id': 1479, 'geoEntityId': 1335, 'dataTypeId...   \n",
       "30  [{'id': 1483, 'geoEntityId': 1339, 'dataTypeId...   \n",
       "31  [{'id': 1484, 'geoEntityId': 1340, 'dataTypeId...   \n",
       "32  [{'id': 1485, 'geoEntityId': 1341, 'dataTypeId...   \n",
       "33  [{'id': 1486, 'geoEntityId': 1342, 'dataTypeId...   \n",
       "34  [{'id': 3573, 'geoEntityId': 8227, 'dataTypeId...   \n",
       "35  [{'id': 9882, 'geoEntityId': 14453, 'dataTypeI...   \n",
       "36  [{'id': 9883, 'geoEntityId': 14454, 'dataTypeI...   \n",
       "\n",
       "    stationWaterLevelStatisticsType  \n",
       "0                                 4  \n",
       "1                                 3  \n",
       "2                                 2  \n",
       "3                                 4  \n",
       "4                                 2  \n",
       "5                                 4  \n",
       "6                                 2  \n",
       "7                                 2  \n",
       "8                                 4  \n",
       "9                                 2  \n",
       "10                                2  \n",
       "11                                4  \n",
       "12                                4  \n",
       "13                                4  \n",
       "14                                2  \n",
       "15                                2  \n",
       "16                                4  \n",
       "17                                2  \n",
       "18                                4  \n",
       "19                                2  \n",
       "20                                2  \n",
       "21                                2  \n",
       "22                                4  \n",
       "23                                2  \n",
       "24                                2  \n",
       "25                                2  \n",
       "26                                2  \n",
       "27                                2  \n",
       "28                                4  \n",
       "29                                2  \n",
       "30                                2  \n",
       "31                                2  \n",
       "32                                2  \n",
       "33                                2  \n",
       "34                                2  \n",
       "35                                2  \n",
       "36                                2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_gauge_ids = df_info['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[380,\n",
       " 382,\n",
       " 384,\n",
       " 386,\n",
       " 387,\n",
       " 391,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 1349,\n",
       " 1351,\n",
       " 1352,\n",
       " 8256,\n",
       " 8340,\n",
       " 16446,\n",
       " 17891,\n",
       " 355,\n",
       " 357,\n",
       " 358,\n",
       " 361,\n",
       " 362,\n",
       " 364,\n",
       " 365,\n",
       " 370,\n",
       " 375,\n",
       " 1335,\n",
       " 1339,\n",
       " 1340,\n",
       " 1341,\n",
       " 1342,\n",
       " 8227,\n",
       " 14453,\n",
       " 14454]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "river_gauge_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for station 380 saved successfully in data/river_data/highest_granularity/station_380.csv.\n",
      "Data for station 382 saved successfully in data/river_data/highest_granularity/station_382.csv.\n",
      "Data for station 384 saved successfully in data/river_data/highest_granularity/station_384.csv.\n",
      "Failed to fetch data for station 386. Status code: 500\n",
      "Data for station 387 saved successfully in data/river_data/highest_granularity/station_387.csv.\n",
      "Failed to fetch data for station 391. Status code: 500\n",
      "Data for station 393 saved successfully in data/river_data/highest_granularity/station_393.csv.\n",
      "Data for station 394 saved successfully in data/river_data/highest_granularity/station_394.csv.\n",
      "Data for station 395 saved successfully in data/river_data/highest_granularity/station_395.csv.\n",
      "Data for station 397 saved successfully in data/river_data/highest_granularity/station_397.csv.\n",
      "Data for station 398 saved successfully in data/river_data/highest_granularity/station_398.csv.\n",
      "Failed to fetch data for station 399. Status code: 500\n",
      "Data for station 400 saved successfully in data/river_data/highest_granularity/station_400.csv.\n",
      "Failed to fetch data for station 1349. Status code: 500\n",
      "Data for station 1351 saved successfully in data/river_data/highest_granularity/station_1351.csv.\n",
      "Data for station 1352 saved successfully in data/river_data/highest_granularity/station_1352.csv.\n",
      "Data for station 8256 saved successfully in data/river_data/highest_granularity/station_8256.csv.\n",
      "Data for station 8340 saved successfully in data/river_data/highest_granularity/station_8340.csv.\n",
      "Failed to fetch data for station 16446. Status code: 500\n",
      "Data for station 17891 saved successfully in data/river_data/highest_granularity/station_17891.csv.\n",
      "Data for station 355 saved successfully in data/river_data/highest_granularity/station_355.csv.\n",
      "Data for station 357 saved successfully in data/river_data/highest_granularity/station_357.csv.\n",
      "Failed to fetch data for station 358. Status code: 500\n",
      "Data for station 361 saved successfully in data/river_data/highest_granularity/station_361.csv.\n",
      "Data for station 362 saved successfully in data/river_data/highest_granularity/station_362.csv.\n",
      "Data for station 364 saved successfully in data/river_data/highest_granularity/station_364.csv.\n",
      "Data for station 365 saved successfully in data/river_data/highest_granularity/station_365.csv.\n",
      "Data for station 370 saved successfully in data/river_data/highest_granularity/station_370.csv.\n",
      "Failed to fetch data for station 375. Status code: 500\n",
      "Data for station 1335 saved successfully in data/river_data/highest_granularity/station_1335.csv.\n",
      "Data for station 1339 saved successfully in data/river_data/highest_granularity/station_1339.csv.\n",
      "Data for station 1340 saved successfully in data/river_data/highest_granularity/station_1340.csv.\n",
      "Data for station 1341 saved successfully in data/river_data/highest_granularity/station_1341.csv.\n",
      "Data for station 1342 saved successfully in data/river_data/highest_granularity/station_1342.csv.\n",
      "Data for station 8227 saved successfully in data/river_data/highest_granularity/station_8227.csv.\n",
      "Data for station 14453 saved successfully in data/river_data/highest_granularity/station_14453.csv.\n",
      "Data for station 14454 saved successfully in data/river_data/highest_granularity/station_14454.csv.\n"
     ]
    }
   ],
   "source": [
    "dc.fetch_and_save_river_data(river_gauge_ids, start_date=date_iso8601, end_date=today, smoothing=0, destination='data/river_data/highest_granularity/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ../data/river_data/highest_granularity/station_362.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_362_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1339.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1339_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_14454.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_14454_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_361.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_361_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_8256.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_8256_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_364.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_364_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_370.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_370_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_365.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_365_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_398.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_398_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_400.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_400_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_14453.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_14453_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_8340.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_8340_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_17891.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_17891_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_8227.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_8227_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1352.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1352_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1351.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1351_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1340.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1340_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1341.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1341_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1342.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1342_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_394.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_394_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_380.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_380_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_357.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_357_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_395.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_395_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_397.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_397_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_355.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_355_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_382.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_382_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_393.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_393_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_387.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_387_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_1335.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_1335_clean.csv\n",
      "Processing file: ../data/river_data/highest_granularity/station_384.csv\n",
      "Saved cleaned data to ../data/river_data/highest_granularity_cleaned/station_384_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "def extract_time_values_from_csv(path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"Extracts time and measurement values from the CSV based on the API response format\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Read in the 'values' column\n",
    "        df = pd.read_csv(path, usecols=[\"values\"])\n",
    "        \n",
    "        # Convert string representations of lists to actual lists of dictionaries\n",
    "        df[\"values\"] = df[\"values\"].apply(literal_eval)\n",
    "        \n",
    "        # Explode the list in the 'values' column to individual rows\n",
    "        df = df.explode(\"values\")\n",
    "        \n",
    "        # Check if \"values\" column contains dictionaries with \"time\" keys\n",
    "        if isinstance(df[\"values\"].iloc[0], dict) and \"time\" in df[\"values\"].iloc[0]:\n",
    "            # Convert dictionaries to separate columns\n",
    "            df = pd.concat([df.drop(\"values\", axis=1), df[\"values\"].apply(pd.Series)], axis=1)\n",
    "        \n",
    "        # Ensure \"time\" column is in datetime format\n",
    "        if \"time\" in df.columns:\n",
    "            df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "\n",
    "        # Set \"time\" as index if it's not already done\n",
    "        if \"time\" in df.columns:\n",
    "            df = df.set_index(\"time\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_time_values_from_csv with file {path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "\n",
    "# Directory containing the files\n",
    "input_directory = '../data/river_data/highest_granularity'\n",
    "output_directory = '../data/river_data/highest_granularity_cleaned'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process each file in the directory\n",
    "for file in os.listdir(input_directory):\n",
    "    # Full path to the input file\n",
    "    file_path = os.path.join(input_directory, file)\n",
    "    \n",
    "    # Debugging: Print which file is being processed\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract time series data\n",
    "        extracted_time_series_df = extract_time_values_from_csv(file_path)\n",
    "        \n",
    "        # Verify if the resulting DataFrame has data and a 'time' column\n",
    "        if extracted_time_series_df.empty:\n",
    "            print(f\"Warning: Data extraction failed for {file}. Empty DataFrame returned.\")\n",
    "            continue\n",
    "        elif \"time\" not in extracted_time_series_df.index.names:\n",
    "            print(f\"Warning: 'time' index is missing in {file}. Skipping file.\")\n",
    "            continue\n",
    "        \n",
    "        # Full path to save the cleaned CSV\n",
    "        output_file_path = os.path.join(output_directory, f\"{os.path.splitext(file)[0]}_clean.csv\")\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        extracted_time_series_df.to_csv(output_file_path)\n",
    "        print(f\"Saved cleaned data to {output_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows across all files: 6510306\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the row counter\n",
    "total_rows = 0\n",
    "\n",
    "# Directory containing the cleaned files\n",
    "directory = '../data/river_data/highest_granularity_cleaned'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in os.listdir(directory):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory, file)\n",
    "    \n",
    "    # Read the CSV file and count the rows\n",
    "    df = pd.read_csv(file_path)\n",
    "    total_rows += len(df)\n",
    "\n",
    "print(f\"Total rows across all files: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Memory (Approx.) MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>station_397_clean.csv</td>\n",
       "      <td>255255</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>99418.815651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>station_1352_clean.csv</td>\n",
       "      <td>203692</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>63309.373267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>station_17891_clean.csv</td>\n",
       "      <td>169004</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>43582.690454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>station_400_clean.csv</td>\n",
       "      <td>227776</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>79165.506250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>station_1340_clean.csv</td>\n",
       "      <td>217307</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>72055.560683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>station_355_clean.csv</td>\n",
       "      <td>229667</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>80485.429213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>station_382_clean.csv</td>\n",
       "      <td>250546</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>95784.451471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>station_1341_clean.csv</td>\n",
       "      <td>208544</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>66361.389063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>station_384_clean.csv</td>\n",
       "      <td>185180</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>52324.878540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>station_361_clean.csv</td>\n",
       "      <td>240814</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>88487.827448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>station_395_clean.csv</td>\n",
       "      <td>152195</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>35344.418373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>station_364_clean.csv</td>\n",
       "      <td>270233</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>111428.641188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>station_370_clean.csv</td>\n",
       "      <td>252928</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>97614.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>station_8227_clean.csv</td>\n",
       "      <td>169239</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>43703.978151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>station_398_clean.csv</td>\n",
       "      <td>211512</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>68263.742285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>station_8340_clean.csv</td>\n",
       "      <td>244112</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>90928.144141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>station_393_clean.csv</td>\n",
       "      <td>191031</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>55683.659303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>station_387_clean.csv</td>\n",
       "      <td>284211</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>123254.230531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>station_1342_clean.csv</td>\n",
       "      <td>260239</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>103339.137453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>station_8256_clean.csv</td>\n",
       "      <td>181296</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>50152.953516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>station_357_clean.csv</td>\n",
       "      <td>225513</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>77600.270338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>station_1335_clean.csv</td>\n",
       "      <td>262402</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>105064.101569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>station_362_clean.csv</td>\n",
       "      <td>244103</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>90921.439528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>station_14454_clean.csv</td>\n",
       "      <td>187912</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>53880.187598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>station_380_clean.csv</td>\n",
       "      <td>94553</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>13641.769118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>station_1351_clean.csv</td>\n",
       "      <td>180768</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>49861.251563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>station_394_clean.csv</td>\n",
       "      <td>166027</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>42060.798232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>station_14453_clean.csv</td>\n",
       "      <td>229855</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>80617.250099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>station_365_clean.csv</td>\n",
       "      <td>265358</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>107444.562018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>station_1339_clean.csv</td>\n",
       "      <td>249034</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>94631.856012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       File    Rows        Columns  Memory (Approx.) MB\n",
       "0     station_397_clean.csv  255255  [time, value]         99418.815651\n",
       "1    station_1352_clean.csv  203692  [time, value]         63309.373267\n",
       "2   station_17891_clean.csv  169004  [time, value]         43582.690454\n",
       "3     station_400_clean.csv  227776  [time, value]         79165.506250\n",
       "4    station_1340_clean.csv  217307  [time, value]         72055.560683\n",
       "5     station_355_clean.csv  229667  [time, value]         80485.429213\n",
       "6     station_382_clean.csv  250546  [time, value]         95784.451471\n",
       "7    station_1341_clean.csv  208544  [time, value]         66361.389063\n",
       "8     station_384_clean.csv  185180  [time, value]         52324.878540\n",
       "9     station_361_clean.csv  240814  [time, value]         88487.827448\n",
       "10    station_395_clean.csv  152195  [time, value]         35344.418373\n",
       "11    station_364_clean.csv  270233  [time, value]        111428.641188\n",
       "12    station_370_clean.csv  252928  [time, value]         97614.400000\n",
       "13   station_8227_clean.csv  169239  [time, value]         43703.978151\n",
       "14    station_398_clean.csv  211512  [time, value]         68263.742285\n",
       "15   station_8340_clean.csv  244112  [time, value]         90928.144141\n",
       "16    station_393_clean.csv  191031  [time, value]         55683.659303\n",
       "17    station_387_clean.csv  284211  [time, value]        123254.230531\n",
       "18   station_1342_clean.csv  260239  [time, value]        103339.137453\n",
       "19   station_8256_clean.csv  181296  [time, value]         50152.953516\n",
       "20    station_357_clean.csv  225513  [time, value]         77600.270338\n",
       "21   station_1335_clean.csv  262402  [time, value]        105064.101569\n",
       "22    station_362_clean.csv  244103  [time, value]         90921.439528\n",
       "23  station_14454_clean.csv  187912  [time, value]         53880.187598\n",
       "24    station_380_clean.csv   94553  [time, value]         13641.769118\n",
       "25   station_1351_clean.csv  180768  [time, value]         49861.251563\n",
       "26    station_394_clean.csv  166027  [time, value]         42060.798232\n",
       "27  station_14453_clean.csv  229855  [time, value]         80617.250099\n",
       "28    station_365_clean.csv  265358  [time, value]        107444.562018\n",
       "29   station_1339_clean.csv  249034  [time, value]         94631.856012"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing your cleaned high-granularity CSV files\n",
    "directory = '../data/river_data/highest_granularity_cleaned'\n",
    "\n",
    "# Initialize lists to collect summary information\n",
    "file_summaries = []\n",
    "\n",
    "# Process each file in the directory\n",
    "for file in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, file)\n",
    "    \n",
    "    try:\n",
    "        # Load a small portion of each CSV for a quick inspection\n",
    "        df = pd.read_csv(file_path, nrows=5)  # Load just the first 5 rows to check columns and dtypes\n",
    "        \n",
    "        # Full row count and memory usage\n",
    "        row_count = sum(1 for _ in open(file_path)) - 1  # Exclude header row for total row count\n",
    "        memory_usage = pd.read_csv(file_path, usecols=[0]).memory_usage(index=False).sum() * row_count / 5  # Approximate memory\n",
    "        \n",
    "        # Collect summary information\n",
    "        summary = {\n",
    "            'File': file,\n",
    "            'Rows': row_count,\n",
    "            'Columns': df.columns.tolist(),\n",
    "            'Memory (Approx.) MB': memory_usage / (1024 ** 2)  # Convert to MB\n",
    "        }\n",
    "        file_summaries.append(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Convert the summaries into a DataFrame for easy viewing\n",
    "summary_df = pd.DataFrame(file_summaries)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2236412.713052368)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['Memory (Approx.) MB'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Memory (MB)</th>\n",
       "      <th>Data Types</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>station_397_clean.csv</td>\n",
       "      <td>255255</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.895008</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.13882958218252334}</td>\n",
       "      <td>{'value': -0.772}</td>\n",
       "      <td>{'value': 1.319}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>station_1352_clean.csv</td>\n",
       "      <td>203692</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.108219</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.22930751821377376}</td>\n",
       "      <td>{'value': 0.116}</td>\n",
       "      <td>{'value': 0.744}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>station_17891_clean.csv</td>\n",
       "      <td>169004</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.578922</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 1.1723450865068283}</td>\n",
       "      <td>{'value': -0.304}</td>\n",
       "      <td>{'value': 2.661}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>station_400_clean.csv</td>\n",
       "      <td>227776</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.475712</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.055048332572351796}</td>\n",
       "      <td>{'value': -0.005}</td>\n",
       "      <td>{'value': 0.558}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>station_1340_clean.csv</td>\n",
       "      <td>217307</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.315968</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.11420882438209538}</td>\n",
       "      <td>{'value': -0.695}</td>\n",
       "      <td>{'value': 3.236}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>station_355_clean.csv</td>\n",
       "      <td>229667</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.504566</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.33112979661858255}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.249}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>station_382_clean.csv</td>\n",
       "      <td>250546</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.823154</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.06620053004238742}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 0.836}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>station_1341_clean.csv</td>\n",
       "      <td>208544</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.182255</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.1400035771827528}</td>\n",
       "      <td>{'value': 0.045}</td>\n",
       "      <td>{'value': 0.49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>station_384_clean.csv</td>\n",
       "      <td>185180</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.825748</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.35118132087698456}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.524}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>station_361_clean.csv</td>\n",
       "      <td>240814</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.674656</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': -0.29486783575705916}</td>\n",
       "      <td>{'value': -1708546.625}</td>\n",
       "      <td>{'value': 1345544.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>station_395_clean.csv</td>\n",
       "      <td>152195</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.322437</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.4195281842373271}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.167}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>station_364_clean.csv</td>\n",
       "      <td>270233</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>4.123554</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.27546297824469995}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 2.992}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>station_370_clean.csv</td>\n",
       "      <td>252928</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.859501</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.44084527612601215}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.224}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>station_8227_clean.csv</td>\n",
       "      <td>169239</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.582508</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.5154296231955992}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.178}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>station_398_clean.csv</td>\n",
       "      <td>211512</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.227543</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.2659894994137449}</td>\n",
       "      <td>{'value': -0.074}</td>\n",
       "      <td>{'value': 2.485}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>station_8340_clean.csv</td>\n",
       "      <td>244112</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.724979</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.44432885724585436}</td>\n",
       "      <td>{'value': -1.106}</td>\n",
       "      <td>{'value': 1.435}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>station_393_clean.csv</td>\n",
       "      <td>191031</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.915028</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.23947240500232947}</td>\n",
       "      <td>{'value': -3.462}</td>\n",
       "      <td>{'value': 1.26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>station_387_clean.csv</td>\n",
       "      <td>284211</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>4.336842</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.21427162917691436}</td>\n",
       "      <td>{'value': -1.0}</td>\n",
       "      <td>{'value': 0.99}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>station_1342_clean.csv</td>\n",
       "      <td>260239</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.971058</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 10.832696340671458}</td>\n",
       "      <td>{'value': 0.061}</td>\n",
       "      <td>{'value': 1370678.125}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>station_8256_clean.csv</td>\n",
       "      <td>181296</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.766483</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.11409388513811666}</td>\n",
       "      <td>{'value': -1.058}</td>\n",
       "      <td>{'value': 0.824}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>station_357_clean.csv</td>\n",
       "      <td>225513</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.441181</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.34058289766000177}</td>\n",
       "      <td>{'value': -0.001}</td>\n",
       "      <td>{'value': 1.329}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>station_1335_clean.csv</td>\n",
       "      <td>262402</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>4.004063</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.5041490499310219}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 2.044}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>station_362_clean.csv</td>\n",
       "      <td>244103</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.724842</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': -1.2096224544557004}</td>\n",
       "      <td>{'value': -1449531.875}</td>\n",
       "      <td>{'value': 1086351.25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>station_14454_clean.csv</td>\n",
       "      <td>187912</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.867435</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.30351081357231047}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 0.753}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>station_380_clean.csv</td>\n",
       "      <td>94553</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>1.442890</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.8024418580055629}</td>\n",
       "      <td>{'value': 0.41}</td>\n",
       "      <td>{'value': 2.649}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>station_1351_clean.csv</td>\n",
       "      <td>180768</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.758427</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.07093432465923173}</td>\n",
       "      <td>{'value': -1.277}</td>\n",
       "      <td>{'value': 1.869}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>station_394_clean.csv</td>\n",
       "      <td>166027</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>2.533497</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.17527247977738558}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.295}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>station_14453_clean.csv</td>\n",
       "      <td>229855</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.507435</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.13639124230493135}</td>\n",
       "      <td>{'value': -0.848}</td>\n",
       "      <td>{'value': 3.053}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>station_365_clean.csv</td>\n",
       "      <td>265358</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>4.049168</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.4164280820627228}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 1.244}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>station_1339_clean.csv</td>\n",
       "      <td>249034</td>\n",
       "      <td>[time, value]</td>\n",
       "      <td>3.800083</td>\n",
       "      <td>{'time': object, 'value': float64}</td>\n",
       "      <td>{'value': 0.8038769404980846}</td>\n",
       "      <td>{'value': -32.768}</td>\n",
       "      <td>{'value': 3.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       File    Rows        Columns  Memory (MB)  \\\n",
       "0     station_397_clean.csv  255255  [time, value]     3.895008   \n",
       "1    station_1352_clean.csv  203692  [time, value]     3.108219   \n",
       "2   station_17891_clean.csv  169004  [time, value]     2.578922   \n",
       "3     station_400_clean.csv  227776  [time, value]     3.475712   \n",
       "4    station_1340_clean.csv  217307  [time, value]     3.315968   \n",
       "5     station_355_clean.csv  229667  [time, value]     3.504566   \n",
       "6     station_382_clean.csv  250546  [time, value]     3.823154   \n",
       "7    station_1341_clean.csv  208544  [time, value]     3.182255   \n",
       "8     station_384_clean.csv  185180  [time, value]     2.825748   \n",
       "9     station_361_clean.csv  240814  [time, value]     3.674656   \n",
       "10    station_395_clean.csv  152195  [time, value]     2.322437   \n",
       "11    station_364_clean.csv  270233  [time, value]     4.123554   \n",
       "12    station_370_clean.csv  252928  [time, value]     3.859501   \n",
       "13   station_8227_clean.csv  169239  [time, value]     2.582508   \n",
       "14    station_398_clean.csv  211512  [time, value]     3.227543   \n",
       "15   station_8340_clean.csv  244112  [time, value]     3.724979   \n",
       "16    station_393_clean.csv  191031  [time, value]     2.915028   \n",
       "17    station_387_clean.csv  284211  [time, value]     4.336842   \n",
       "18   station_1342_clean.csv  260239  [time, value]     3.971058   \n",
       "19   station_8256_clean.csv  181296  [time, value]     2.766483   \n",
       "20    station_357_clean.csv  225513  [time, value]     3.441181   \n",
       "21   station_1335_clean.csv  262402  [time, value]     4.004063   \n",
       "22    station_362_clean.csv  244103  [time, value]     3.724842   \n",
       "23  station_14454_clean.csv  187912  [time, value]     2.867435   \n",
       "24    station_380_clean.csv   94553  [time, value]     1.442890   \n",
       "25   station_1351_clean.csv  180768  [time, value]     2.758427   \n",
       "26    station_394_clean.csv  166027  [time, value]     2.533497   \n",
       "27  station_14453_clean.csv  229855  [time, value]     3.507435   \n",
       "28    station_365_clean.csv  265358  [time, value]     4.049168   \n",
       "29   station_1339_clean.csv  249034  [time, value]     3.800083   \n",
       "\n",
       "                            Data Types                             Mean  \\\n",
       "0   {'time': object, 'value': float64}   {'value': 0.13882958218252334}   \n",
       "1   {'time': object, 'value': float64}   {'value': 0.22930751821377376}   \n",
       "2   {'time': object, 'value': float64}    {'value': 1.1723450865068283}   \n",
       "3   {'time': object, 'value': float64}  {'value': 0.055048332572351796}   \n",
       "4   {'time': object, 'value': float64}   {'value': 0.11420882438209538}   \n",
       "5   {'time': object, 'value': float64}   {'value': 0.33112979661858255}   \n",
       "6   {'time': object, 'value': float64}   {'value': 0.06620053004238742}   \n",
       "7   {'time': object, 'value': float64}    {'value': 0.1400035771827528}   \n",
       "8   {'time': object, 'value': float64}   {'value': 0.35118132087698456}   \n",
       "9   {'time': object, 'value': float64}  {'value': -0.29486783575705916}   \n",
       "10  {'time': object, 'value': float64}    {'value': 0.4195281842373271}   \n",
       "11  {'time': object, 'value': float64}   {'value': 0.27546297824469995}   \n",
       "12  {'time': object, 'value': float64}   {'value': 0.44084527612601215}   \n",
       "13  {'time': object, 'value': float64}    {'value': 0.5154296231955992}   \n",
       "14  {'time': object, 'value': float64}    {'value': 0.2659894994137449}   \n",
       "15  {'time': object, 'value': float64}   {'value': 0.44432885724585436}   \n",
       "16  {'time': object, 'value': float64}   {'value': 0.23947240500232947}   \n",
       "17  {'time': object, 'value': float64}   {'value': 0.21427162917691436}   \n",
       "18  {'time': object, 'value': float64}    {'value': 10.832696340671458}   \n",
       "19  {'time': object, 'value': float64}   {'value': 0.11409388513811666}   \n",
       "20  {'time': object, 'value': float64}   {'value': 0.34058289766000177}   \n",
       "21  {'time': object, 'value': float64}    {'value': 0.5041490499310219}   \n",
       "22  {'time': object, 'value': float64}   {'value': -1.2096224544557004}   \n",
       "23  {'time': object, 'value': float64}   {'value': 0.30351081357231047}   \n",
       "24  {'time': object, 'value': float64}    {'value': 0.8024418580055629}   \n",
       "25  {'time': object, 'value': float64}   {'value': 0.07093432465923173}   \n",
       "26  {'time': object, 'value': float64}   {'value': 0.17527247977738558}   \n",
       "27  {'time': object, 'value': float64}   {'value': 0.13639124230493135}   \n",
       "28  {'time': object, 'value': float64}    {'value': 0.4164280820627228}   \n",
       "29  {'time': object, 'value': float64}    {'value': 0.8038769404980846}   \n",
       "\n",
       "                        Min                     Max  \n",
       "0         {'value': -0.772}        {'value': 1.319}  \n",
       "1          {'value': 0.116}        {'value': 0.744}  \n",
       "2         {'value': -0.304}        {'value': 2.661}  \n",
       "3         {'value': -0.005}        {'value': 0.558}  \n",
       "4         {'value': -0.695}        {'value': 3.236}  \n",
       "5        {'value': -32.768}        {'value': 1.249}  \n",
       "6        {'value': -32.768}        {'value': 0.836}  \n",
       "7          {'value': 0.045}         {'value': 0.49}  \n",
       "8        {'value': -32.768}        {'value': 1.524}  \n",
       "9   {'value': -1708546.625}    {'value': 1345544.5}  \n",
       "10       {'value': -32.768}        {'value': 1.167}  \n",
       "11       {'value': -32.768}        {'value': 2.992}  \n",
       "12       {'value': -32.768}        {'value': 1.224}  \n",
       "13       {'value': -32.768}        {'value': 1.178}  \n",
       "14        {'value': -0.074}        {'value': 2.485}  \n",
       "15        {'value': -1.106}        {'value': 1.435}  \n",
       "16        {'value': -3.462}         {'value': 1.26}  \n",
       "17          {'value': -1.0}         {'value': 0.99}  \n",
       "18         {'value': 0.061}  {'value': 1370678.125}  \n",
       "19        {'value': -1.058}        {'value': 0.824}  \n",
       "20        {'value': -0.001}        {'value': 1.329}  \n",
       "21       {'value': -32.768}        {'value': 2.044}  \n",
       "22  {'value': -1449531.875}   {'value': 1086351.25}  \n",
       "23       {'value': -32.768}        {'value': 0.753}  \n",
       "24          {'value': 0.41}        {'value': 2.649}  \n",
       "25        {'value': -1.277}        {'value': 1.869}  \n",
       "26       {'value': -32.768}        {'value': 1.295}  \n",
       "27        {'value': -0.848}        {'value': 3.053}  \n",
       "28       {'value': -32.768}        {'value': 1.244}  \n",
       "29       {'value': -32.768}          {'value': 3.0}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the cleaned high-granularity CSV files\n",
    "directory = '../data/river_data/highest_granularity_cleaned'\n",
    "\n",
    "# Initialize a list to collect summary information\n",
    "file_summaries = []\n",
    "\n",
    "# Process each file in the directory\n",
    "for file in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, file)\n",
    "    \n",
    "    try:\n",
    "        # Load the first few rows for column inspection and memory usage approximation\n",
    "        df_sample = pd.read_csv(file_path, nrows=5)  # Load only 5 rows for initial inspection\n",
    "        df_full = pd.read_csv(file_path)  # Full file loading for stats if manageable\n",
    "        \n",
    "        # Row count and memory usage\n",
    "        row_count = len(df_full)\n",
    "        memory_usage = df_full.memory_usage(index=True).sum() / (1024 ** 2)  # Memory in MB\n",
    "        \n",
    "        # Summary stats for numeric columns\n",
    "        stats = df_full.describe().to_dict()\n",
    "        \n",
    "        # Extract specific summary stats\n",
    "        summary = {\n",
    "            'File': file,\n",
    "            'Rows': row_count,\n",
    "            'Columns': df_sample.columns.tolist(),\n",
    "            'Memory (MB)': memory_usage,\n",
    "            'Data Types': df_sample.dtypes.to_dict(),\n",
    "            'Mean': {col: stats[col]['mean'] for col in stats if 'mean' in stats[col]},\n",
    "            'Min': {col: stats[col]['min'] for col in stats if 'min' in stats[col]},\n",
    "            'Max': {col: stats[col]['max'] for col in stats if 'max' in stats[col]}\n",
    "        }\n",
    "        file_summaries.append(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Convert the summaries into a DataFrame for easy viewing\n",
    "summary_df = pd.DataFrame(file_summaries)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_362 = pd.read_csv('data/river_data/highest_granularity/station_362_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import clean_river_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/river_data/highest_granularity/station_362_clean.csv\n",
      "Rows dropped due to unparseable 'time' values: 0 (0.00%)\n",
      "The resampling to 15 created 66475 rows corresponding to missing timestamps\n",
      "Total missing 15-minute rows: 66475 (21.40%)\n",
      "\n",
      "Negative values replaced and missing values filled using linear interpolation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_clean_362 = clean_river_csv('data/river_data/highest_granularity/station_362_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/river_data/highest_granularity/station_362_clean.csv\n",
      "Rows dropped due to unparseable 'time' values: 0 (0.00%)\n",
      "The resampling to 15 created 66475 rows corresponding to missing timestamps\n",
      "Total missing 15-minute rows: 66475 (21.40%)\n",
      "\n",
      "Negative values replaced and missing values filled using linear interpolation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, test_clean_362 = clean_river_csv('data/river_data/highest_granularity/station_362_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: data/river_data/station_362_clean.csv\n",
      "Rows dropped due to unparseable 'time' values: 0 (0.00%)\n",
      "The resampling to 15 created 106945 rows corresponding to missing timestamps\n",
      "Total missing 15-minute rows: 106945 (29.45%)\n",
      "\n",
      "Negative values replaced and missing values filled using linear interpolation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, test_clean_362_low_gran = clean_river_csv('data/river_data/station_362_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00+00:00</th>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:15:00+00:00</th>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:30:00+00:00</th>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:45:00+00:00</th>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00+00:00</th>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:15:00+00:00</th>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:30:00+00:00</th>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:45:00+00:00</th>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 04:00:00+00:00</th>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 04:15:00+00:00</th>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310578 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "time                            \n",
       "2016-01-01 00:00:00+00:00  0.431\n",
       "2016-01-01 00:15:00+00:00  0.432\n",
       "2016-01-01 00:30:00+00:00  0.431\n",
       "2016-01-01 00:45:00+00:00  0.430\n",
       "2016-01-01 01:00:00+00:00  0.429\n",
       "...                          ...\n",
       "2024-11-09 03:15:00+00:00  0.216\n",
       "2024-11-09 03:30:00+00:00  0.214\n",
       "2024-11-09 03:45:00+00:00  0.214\n",
       "2024-11-09 04:00:00+00:00  0.216\n",
       "2024-11-09 04:15:00+00:00  0.215\n",
       "\n",
       "[310578 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-04 04:15:00+00:00</th>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 04:30:00+00:00</th>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 04:45:00+00:00</th>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 05:00:00+00:00</th>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-04 05:15:00+00:00</th>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-11 22:45:00+00:00</th>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-11 23:00:00+00:00</th>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-11 23:15:00+00:00</th>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-11 23:30:00+00:00</th>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-11 23:45:00+00:00</th>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363151 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "time                            \n",
       "2014-03-04 04:15:00+00:00  0.571\n",
       "2014-03-04 04:30:00+00:00  0.572\n",
       "2014-03-04 04:45:00+00:00  0.571\n",
       "2014-03-04 05:00:00+00:00  0.570\n",
       "2014-03-04 05:15:00+00:00  0.571\n",
       "...                          ...\n",
       "2024-07-11 22:45:00+00:00  0.188\n",
       "2024-07-11 23:00:00+00:00  0.188\n",
       "2024-07-11 23:15:00+00:00  0.188\n",
       "2024-07-11 23:30:00+00:00  0.188\n",
       "2024-07-11 23:45:00+00:00  0.189\n",
       "\n",
       "[363151 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_362_low_gran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.105780e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.513751e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.179415e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.560000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.450000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.800000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.086351e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value\n",
       "count  3.105780e+05\n",
       "mean   5.513751e+00\n",
       "std    2.179415e+03\n",
       "min    3.000000e-02\n",
       "25%    1.560000e-01\n",
       "50%    2.450000e-01\n",
       "75%    3.800000e-01\n",
       "max    1.086351e+06"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_362.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Rows (smoothing=0)</th>\n",
       "      <th>Rows (smoothing=2)</th>\n",
       "      <th>Time Gap (smoothing=0)</th>\n",
       "      <th>Time Gap (smoothing=2)</th>\n",
       "      <th>Mean (smoothing=0)</th>\n",
       "      <th>Mean (smoothing=2)</th>\n",
       "      <th>Min (smoothing=0)</th>\n",
       "      <th>Min (smoothing=2)</th>\n",
       "      <th>Max (smoothing=0)</th>\n",
       "      <th>Max (smoothing=2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>station_397_clean.csv</td>\n",
       "      <td>255255</td>\n",
       "      <td>272726</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.138830</td>\n",
       "      <td>0.131770</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>1.319</td>\n",
       "      <td>1.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>station_1352_clean.csv</td>\n",
       "      <td>203692</td>\n",
       "      <td>225361</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.229308</td>\n",
       "      <td>0.225516</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>station_17891_clean.csv</td>\n",
       "      <td>169004</td>\n",
       "      <td>135251</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>1.172345</td>\n",
       "      <td>1.159680</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>2.661</td>\n",
       "      <td>2.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>station_400_clean.csv</td>\n",
       "      <td>227776</td>\n",
       "      <td>245281</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.055048</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>station_1340_clean.csv</td>\n",
       "      <td>217307</td>\n",
       "      <td>244191</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.114209</td>\n",
       "      <td>0.108532</td>\n",
       "      <td>-0.695</td>\n",
       "      <td>-0.695</td>\n",
       "      <td>3.236</td>\n",
       "      <td>3.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>station_355_clean.csv</td>\n",
       "      <td>229667</td>\n",
       "      <td>244105</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.331130</td>\n",
       "      <td>0.331719</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.249</td>\n",
       "      <td>1.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>station_382_clean.csv</td>\n",
       "      <td>250546</td>\n",
       "      <td>246373</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.066201</td>\n",
       "      <td>0.072932</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>station_1341_clean.csv</td>\n",
       "      <td>208544</td>\n",
       "      <td>238527</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.140004</td>\n",
       "      <td>0.131060</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>station_384_clean.csv</td>\n",
       "      <td>185180</td>\n",
       "      <td>193590</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.351181</td>\n",
       "      <td>0.351539</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.524</td>\n",
       "      <td>1.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>station_361_clean.csv</td>\n",
       "      <td>240814</td>\n",
       "      <td>250455</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>-0.294868</td>\n",
       "      <td>-3.066285</td>\n",
       "      <td>-1708546.625</td>\n",
       "      <td>-1708517.250</td>\n",
       "      <td>1345544.500</td>\n",
       "      <td>32.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>station_395_clean.csv</td>\n",
       "      <td>152195</td>\n",
       "      <td>179864</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.419528</td>\n",
       "      <td>0.420817</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.167</td>\n",
       "      <td>1.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>station_364_clean.csv</td>\n",
       "      <td>270233</td>\n",
       "      <td>290429</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.275463</td>\n",
       "      <td>0.271603</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>2.992</td>\n",
       "      <td>3.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>station_370_clean.csv</td>\n",
       "      <td>252928</td>\n",
       "      <td>273224</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.440845</td>\n",
       "      <td>0.438775</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.224</td>\n",
       "      <td>1.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>station_8227_clean.csv</td>\n",
       "      <td>169239</td>\n",
       "      <td>99233</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.515430</td>\n",
       "      <td>0.497519</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.178</td>\n",
       "      <td>1.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>station_398_clean.csv</td>\n",
       "      <td>211512</td>\n",
       "      <td>200923</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.265989</td>\n",
       "      <td>0.260489</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>station_8340_clean.csv</td>\n",
       "      <td>244112</td>\n",
       "      <td>255640</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.444329</td>\n",
       "      <td>0.446583</td>\n",
       "      <td>-1.106</td>\n",
       "      <td>-1.106</td>\n",
       "      <td>1.435</td>\n",
       "      <td>1.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>station_393_clean.csv</td>\n",
       "      <td>191031</td>\n",
       "      <td>195372</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.239472</td>\n",
       "      <td>0.235897</td>\n",
       "      <td>-3.462</td>\n",
       "      <td>-3.462</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>station_387_clean.csv</td>\n",
       "      <td>284211</td>\n",
       "      <td>299795</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.214272</td>\n",
       "      <td>0.218316</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>station_1342_clean.csv</td>\n",
       "      <td>260239</td>\n",
       "      <td>287601</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>10.832696</td>\n",
       "      <td>5.066193</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.147</td>\n",
       "      <td>1370678.125</td>\n",
       "      <td>1370678.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>station_8256_clean.csv</td>\n",
       "      <td>181296</td>\n",
       "      <td>227880</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.114094</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>-1.058</td>\n",
       "      <td>-1.150</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>station_357_clean.csv</td>\n",
       "      <td>225513</td>\n",
       "      <td>243398</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.340583</td>\n",
       "      <td>0.337578</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.182</td>\n",
       "      <td>1.329</td>\n",
       "      <td>1.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>station_1335_clean.csv</td>\n",
       "      <td>262402</td>\n",
       "      <td>276568</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.504149</td>\n",
       "      <td>0.482313</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>2.044</td>\n",
       "      <td>2.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>station_362_clean.csv</td>\n",
       "      <td>244103</td>\n",
       "      <td>256206</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>-1.209622</td>\n",
       "      <td>-5.376351</td>\n",
       "      <td>-1449531.875</td>\n",
       "      <td>-1449531.875</td>\n",
       "      <td>1086351.250</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>station_14454_clean.csv</td>\n",
       "      <td>187912</td>\n",
       "      <td>97035</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.303511</td>\n",
       "      <td>0.288243</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>station_380_clean.csv</td>\n",
       "      <td>94553</td>\n",
       "      <td>126743</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.802442</td>\n",
       "      <td>0.779587</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.410</td>\n",
       "      <td>2.649</td>\n",
       "      <td>2.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>station_1351_clean.csv</td>\n",
       "      <td>180768</td>\n",
       "      <td>202201</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.070934</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>1.869</td>\n",
       "      <td>3.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>station_394_clean.csv</td>\n",
       "      <td>166027</td>\n",
       "      <td>172134</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.175272</td>\n",
       "      <td>0.166450</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.295</td>\n",
       "      <td>1.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>station_14453_clean.csv</td>\n",
       "      <td>229855</td>\n",
       "      <td>219515</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.136391</td>\n",
       "      <td>0.139007</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>3.053</td>\n",
       "      <td>3.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>station_365_clean.csv</td>\n",
       "      <td>265358</td>\n",
       "      <td>284311</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.416428</td>\n",
       "      <td>0.412028</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>1.244</td>\n",
       "      <td>1.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>station_1339_clean.csv</td>\n",
       "      <td>249034</td>\n",
       "      <td>257863</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0.803877</td>\n",
       "      <td>0.803881</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>-32.768</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       File  Rows (smoothing=0)  Rows (smoothing=2)  \\\n",
       "0     station_397_clean.csv              255255              272726   \n",
       "1    station_1352_clean.csv              203692              225361   \n",
       "2   station_17891_clean.csv              169004              135251   \n",
       "3     station_400_clean.csv              227776              245281   \n",
       "4    station_1340_clean.csv              217307              244191   \n",
       "5     station_355_clean.csv              229667              244105   \n",
       "6     station_382_clean.csv              250546              246373   \n",
       "7    station_1341_clean.csv              208544              238527   \n",
       "8     station_384_clean.csv              185180              193590   \n",
       "9     station_361_clean.csv              240814              250455   \n",
       "10    station_395_clean.csv              152195              179864   \n",
       "11    station_364_clean.csv              270233              290429   \n",
       "12    station_370_clean.csv              252928              273224   \n",
       "13   station_8227_clean.csv              169239               99233   \n",
       "14    station_398_clean.csv              211512              200923   \n",
       "15   station_8340_clean.csv              244112              255640   \n",
       "16    station_393_clean.csv              191031              195372   \n",
       "17    station_387_clean.csv              284211              299795   \n",
       "18   station_1342_clean.csv              260239              287601   \n",
       "19   station_8256_clean.csv              181296              227880   \n",
       "20    station_357_clean.csv              225513              243398   \n",
       "21   station_1335_clean.csv              262402              276568   \n",
       "22    station_362_clean.csv              244103              256206   \n",
       "23  station_14454_clean.csv              187912               97035   \n",
       "24    station_380_clean.csv               94553              126743   \n",
       "25   station_1351_clean.csv              180768              202201   \n",
       "26    station_394_clean.csv              166027              172134   \n",
       "27  station_14453_clean.csv              229855              219515   \n",
       "28    station_365_clean.csv              265358              284311   \n",
       "29   station_1339_clean.csv              249034              257863   \n",
       "\n",
       "   Time Gap (smoothing=0) Time Gap (smoothing=2)  Mean (smoothing=0)  \\\n",
       "0         0 days 00:15:00        0 days 00:15:00            0.138830   \n",
       "1         0 days 00:15:00        0 days 00:15:00            0.229308   \n",
       "2         0 days 00:15:00        0 days 00:15:00            1.172345   \n",
       "3         0 days 00:15:00        0 days 00:15:00            0.055048   \n",
       "4         0 days 00:15:00        0 days 00:15:00            0.114209   \n",
       "5         0 days 00:15:00        0 days 00:15:00            0.331130   \n",
       "6         0 days 00:15:00        0 days 00:15:00            0.066201   \n",
       "7         0 days 00:15:00        0 days 00:15:00            0.140004   \n",
       "8         0 days 00:15:00        0 days 00:15:00            0.351181   \n",
       "9         0 days 00:15:00        0 days 00:15:00           -0.294868   \n",
       "10        0 days 00:15:00        0 days 00:15:00            0.419528   \n",
       "11        0 days 00:15:00        0 days 00:15:00            0.275463   \n",
       "12        0 days 00:15:00        0 days 00:15:00            0.440845   \n",
       "13        0 days 00:15:00        0 days 00:15:00            0.515430   \n",
       "14        0 days 00:15:00        0 days 00:15:00            0.265989   \n",
       "15        0 days 00:15:00        0 days 00:15:00            0.444329   \n",
       "16        0 days 00:15:00        0 days 00:15:00            0.239472   \n",
       "17        0 days 00:15:00        0 days 00:15:00            0.214272   \n",
       "18        0 days 00:15:00        0 days 00:15:00           10.832696   \n",
       "19        0 days 00:15:00        0 days 00:15:00            0.114094   \n",
       "20        0 days 00:15:00        0 days 00:15:00            0.340583   \n",
       "21        0 days 00:15:00        0 days 00:15:00            0.504149   \n",
       "22        0 days 00:15:00        0 days 00:15:00           -1.209622   \n",
       "23        0 days 00:15:00        0 days 00:15:00            0.303511   \n",
       "24        0 days 00:15:00        0 days 00:15:00            0.802442   \n",
       "25        0 days 00:15:00        0 days 00:15:00            0.070934   \n",
       "26        0 days 00:15:00        0 days 00:15:00            0.175272   \n",
       "27        0 days 00:15:00        0 days 00:15:00            0.136391   \n",
       "28        0 days 00:15:00        0 days 00:15:00            0.416428   \n",
       "29        0 days 00:15:00        0 days 00:15:00            0.803877   \n",
       "\n",
       "    Mean (smoothing=2)  Min (smoothing=0)  Min (smoothing=2)  \\\n",
       "0             0.131770             -0.772             -0.772   \n",
       "1             0.225516              0.116              0.097   \n",
       "2             1.159680             -0.304             -0.304   \n",
       "3             0.049444             -0.005             -0.006   \n",
       "4             0.108532             -0.695             -0.695   \n",
       "5             0.331719            -32.768            -32.768   \n",
       "6             0.072932            -32.768            -32.768   \n",
       "7             0.131060              0.045              0.039   \n",
       "8             0.351539            -32.768            -32.768   \n",
       "9            -3.066285       -1708546.625       -1708517.250   \n",
       "10            0.420817            -32.768            -32.768   \n",
       "11            0.271603            -32.768            -32.768   \n",
       "12            0.438775            -32.768            -32.768   \n",
       "13            0.497519            -32.768            -32.768   \n",
       "14            0.260489             -0.074             -0.074   \n",
       "15            0.446583             -1.106             -1.106   \n",
       "16            0.235897             -3.462             -3.462   \n",
       "17            0.218316             -1.000             -1.000   \n",
       "18            5.066193              0.061              0.147   \n",
       "19            0.109371             -1.058             -1.150   \n",
       "20            0.337578             -0.001              0.182   \n",
       "21            0.482313            -32.768            -32.768   \n",
       "22           -5.376351       -1449531.875       -1449531.875   \n",
       "23            0.288243            -32.768            -32.768   \n",
       "24            0.779587              0.410              0.410   \n",
       "25            0.070101             -1.277             -1.277   \n",
       "26            0.166450            -32.768            -32.768   \n",
       "27            0.139007             -0.848             -0.848   \n",
       "28            0.412028            -32.768            -32.768   \n",
       "29            0.803881            -32.768            -32.768   \n",
       "\n",
       "    Max (smoothing=0)  Max (smoothing=2)  \n",
       "0               1.319              1.319  \n",
       "1               0.744              0.744  \n",
       "2               2.661              2.661  \n",
       "3               0.558              0.558  \n",
       "4               3.236              3.236  \n",
       "5               1.249              1.249  \n",
       "6               0.836              0.836  \n",
       "7               0.490              0.490  \n",
       "8               1.524              1.659  \n",
       "9         1345544.500             32.767  \n",
       "10              1.167              1.853  \n",
       "11              2.992              3.223  \n",
       "12              1.224              1.224  \n",
       "13              1.178              1.177  \n",
       "14              2.485              2.485  \n",
       "15              1.435              1.435  \n",
       "16              1.260              1.260  \n",
       "17              0.990              0.990  \n",
       "18        1370678.125        1370678.125  \n",
       "19              0.824              0.824  \n",
       "20              1.329              1.329  \n",
       "21              2.044              2.044  \n",
       "22        1086351.250              0.815  \n",
       "23              0.753              0.753  \n",
       "24              2.649              2.649  \n",
       "25              1.869              3.124  \n",
       "26              1.295              1.295  \n",
       "27              3.053              3.053  \n",
       "28              1.244              1.244  \n",
       "29              3.000              3.000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories for smoothing=0 and smoothing=2 CSVs\n",
    "high_granularity_dir = 'data/river_data/highest_granularity'  # smoothing=0\n",
    "low_granularity_dir = 'data/river_data/'  # smoothing=2\n",
    "\n",
    "# Initialize lists to collect comparison data\n",
    "comparisons = []\n",
    "\n",
    "# Compare each file by name\n",
    "for file in os.listdir(high_granularity_dir):\n",
    "    high_path = os.path.join(high_granularity_dir, file)\n",
    "    low_path = os.path.join(low_granularity_dir, file)\n",
    "\n",
    "    # Ensure both files exist\n",
    "    if os.path.exists(high_path) and os.path.exists(low_path):\n",
    "        # Load the data\n",
    "        df_high = pd.read_csv(high_path, parse_dates=['time'])\n",
    "        df_low = pd.read_csv(low_path, parse_dates=['time'])\n",
    "        \n",
    "        # Row count comparison\n",
    "        high_rows = len(df_high)\n",
    "        low_rows = len(df_low)\n",
    "        \n",
    "        # Time interval comparison\n",
    "        high_time_gap = df_high['time'].diff().median()\n",
    "        low_time_gap = df_low['time'].diff().median()\n",
    "        \n",
    "        # Value statistics comparison\n",
    "        high_mean, high_min, high_max = df_high['value'].mean(), df_high['value'].min(), df_high['value'].max()\n",
    "        low_mean, low_min, low_max = df_low['value'].mean(), df_low['value'].min(), df_low['value'].max()\n",
    "        \n",
    "        # Append to comparison data\n",
    "        comparisons.append({\n",
    "            'File': file,\n",
    "            'Rows (smoothing=0)': high_rows,\n",
    "            'Rows (smoothing=2)': low_rows,\n",
    "            'Time Gap (smoothing=0)': high_time_gap,\n",
    "            'Time Gap (smoothing=2)': low_time_gap,\n",
    "            'Mean (smoothing=0)': high_mean,\n",
    "            'Mean (smoothing=2)': low_mean,\n",
    "            'Min (smoothing=0)': high_min,\n",
    "            'Min (smoothing=2)': low_min,\n",
    "            'Max (smoothing=0)': high_max,\n",
    "            'Max (smoothing=2)': low_max\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame for quick viewing\n",
    "comparison_df = pd.DataFrame(comparisons)\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_361 = pd.read_csv('/Users/antonfreidin/water_project/data/river_data/highest_granularity/station_361_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100093</th>\n",
       "      <td>2019-07-24 19:45:00</td>\n",
       "      <td>-32.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100094</th>\n",
       "      <td>2019-07-24 20:30:00</td>\n",
       "      <td>-32.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170894</th>\n",
       "      <td>2022-01-25 04:45:00</td>\n",
       "      <td>-1708517.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184049</th>\n",
       "      <td>2022-08-05 10:15:00</td>\n",
       "      <td>-32.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236892</th>\n",
       "      <td>2024-07-23 16:45:00</td>\n",
       "      <td>-1708546.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time        value\n",
       "100093  2019-07-24 19:45:00      -32.768\n",
       "100094  2019-07-24 20:30:00      -32.768\n",
       "170894  2022-01-25 04:45:00 -1708517.250\n",
       "184049  2022-08-05 10:15:00      -32.768\n",
       "236892  2024-07-23 16:45:00 -1708546.625"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_361.loc[df_361['value'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /Users/antonfreidin/water_project/data/river_data/highest_granularity/station_361_clean.csv\n",
      "Rows dropped due to unparseable 'time' values: 0 (0.00%)\n",
      "The resampling to 15 created 69763 rows corresponding to missing timestamps\n",
      "Total missing 15-minute rows: 69763 (22.46%)\n",
      "\n",
      "Negative values replaced and missing values filled using linear interpolation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,test_361 = clean_river_csv('/Users/antonfreidin/water_project/data/river_data/highest_granularity/station_361_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.105770e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.115686e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.024130e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.570000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.701000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.855000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345544e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value\n",
       "count  3.105770e+05\n",
       "mean   2.115686e+01\n",
       "std    4.024130e+03\n",
       "min    3.000000e-02\n",
       "25%    3.570000e+00\n",
       "50%    3.701000e+00\n",
       "75%    3.855000e+00\n",
       "max    1.345544e+06"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_361.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-25 04:30:00+00:00</th>\n",
       "      <td>4.485149e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25 04:45:00+00:00</th>\n",
       "      <td>8.970297e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25 05:00:00+00:00</th>\n",
       "      <td>1.345544e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23 16:15:00+00:00</th>\n",
       "      <td>2.716129e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23 16:30:00+00:00</th>\n",
       "      <td>5.432222e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23 16:45:00+00:00</th>\n",
       "      <td>8.148315e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23 17:00:00+00:00</th>\n",
       "      <td>1.086441e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  value\n",
       "time                                   \n",
       "2022-01-25 04:30:00+00:00  4.485149e+05\n",
       "2022-01-25 04:45:00+00:00  8.970297e+05\n",
       "2022-01-25 05:00:00+00:00  1.345544e+06\n",
       "2024-07-23 16:15:00+00:00  2.716129e+05\n",
       "2024-07-23 16:30:00+00:00  5.432222e+05\n",
       "2024-07-23 16:45:00+00:00  8.148315e+05\n",
       "2024-07-23 17:00:00+00:00  1.086441e+06"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = test_361['value'].mean()\n",
    "sd = test_361['value'].std()\n",
    "ridiculous_values = test_361.loc[(test_361['value'] > 10 * sd + mean) |( mean - 10 * sd > test_361['value']) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ridiculous_values_river(df, remove_ridiculous=False):\n",
    "    mean = df['value'].mean()\n",
    "    standard_deviation = df['value'].std()\n",
    "    \n",
    "    # Identify ridiculous values\n",
    "    ridiculous_values = df.loc[(df['value'] > mean + 10 * standard_deviation) | (df['value'] < 0)]\n",
    "    print(f'Ridiculous values from df:\\n{ridiculous_values}')\n",
    "    \n",
    "    # Remove ridiculous values by replacing them with NaN if specified\n",
    "    if remove_ridiculous:\n",
    "        df.loc[(df['value'] > mean + 10 * standard_deviation) | (df['value'] < 0), 'value'] = np.nan\n",
    "        print('This is the df without the erroneous looking values:')\n",
    "    \n",
    "    return df  # Return the modified DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00+00:00</th>\n",
       "      <td>3.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:15:00+00:00</th>\n",
       "      <td>3.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:30:00+00:00</th>\n",
       "      <td>3.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:45:00+00:00</th>\n",
       "      <td>3.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00+00:00</th>\n",
       "      <td>3.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:00:00+00:00</th>\n",
       "      <td>3.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:15:00+00:00</th>\n",
       "      <td>3.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:30:00+00:00</th>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 03:45:00+00:00</th>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09 04:00:00+00:00</th>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310577 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "time                            \n",
       "2016-01-01 00:00:00+00:00  3.919\n",
       "2016-01-01 00:15:00+00:00  3.919\n",
       "2016-01-01 00:30:00+00:00  3.919\n",
       "2016-01-01 00:45:00+00:00  3.918\n",
       "2016-01-01 01:00:00+00:00  3.919\n",
       "...                          ...\n",
       "2024-11-09 03:00:00+00:00  3.697\n",
       "2024-11-09 03:15:00+00:00  3.697\n",
       "2024-11-09 03:30:00+00:00  3.696\n",
       "2024-11-09 03:45:00+00:00  3.696\n",
       "2024-11-09 04:00:00+00:00  3.696\n",
       "\n",
       "[310577 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_ridic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waterfall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
